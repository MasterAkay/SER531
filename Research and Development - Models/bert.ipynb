{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "with open(\"lcquad_2_0.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)\n",
    "    \n",
    "df = pd.json_normalize(data)\n",
    "df[\"template_id\"] = df['template_id'].astype(str)\n",
    "df[\"template_index\"] = df['template_index'].astype(str)\n",
    "df[\"template\"] = df['template'].astype(str)\n",
    "df[\"paraphrased_question\"] = df['paraphrased_question'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[[\"paraphrased_question\",\"template\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paraphrased_question</th>\n",
       "      <th>template</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did Alexander Hamilton practice law?</td>\n",
       "      <td>Ask (ent-pred-obj)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Does FC Barcelona have Juan Jose Ibarretxe as ...</td>\n",
       "      <td>Ask (ent-pred-obj`)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is Harrelson the real family name of Woody Har...</td>\n",
       "      <td>Ask (ent-pred-obj)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Was Ivonka Trump ever a tv host?</td>\n",
       "      <td>Ask (ent-pred-obj)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Has Rihanna ever recorded for Motown?</td>\n",
       "      <td>Ask (ent-pred-obj`)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30221</th>\n",
       "      <td>Which geographic area is located in East Asia'...</td>\n",
       "      <td>&lt;?S P O ; ?S InstanceOf Type&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30222</th>\n",
       "      <td>Which company has Skype developed?</td>\n",
       "      <td>&lt;S P ?O ; ?O instanceOf Type&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30223</th>\n",
       "      <td>Which film is David Bowie's name?</td>\n",
       "      <td>&lt;?S P O ; ?S InstanceOf Type&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30224</th>\n",
       "      <td>What is the federal state involved in the Cuba...</td>\n",
       "      <td>&lt;S P ?O ; ?O instanceOf Type&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30225</th>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;?S P O ; ?S InstanceOf Type&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30226 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    paraphrased_question  \\\n",
       "0                   Did Alexander Hamilton practice law?   \n",
       "1      Does FC Barcelona have Juan Jose Ibarretxe as ...   \n",
       "2      Is Harrelson the real family name of Woody Har...   \n",
       "3                       Was Ivonka Trump ever a tv host?   \n",
       "4                  Has Rihanna ever recorded for Motown?   \n",
       "...                                                  ...   \n",
       "30221  Which geographic area is located in East Asia'...   \n",
       "30222                 Which company has Skype developed?   \n",
       "30223                  Which film is David Bowie's name?   \n",
       "30224  What is the federal state involved in the Cuba...   \n",
       "30225                                                 []   \n",
       "\n",
       "                             template  \n",
       "0                  Ask (ent-pred-obj)  \n",
       "1                 Ask (ent-pred-obj`)  \n",
       "2                  Ask (ent-pred-obj)  \n",
       "3                  Ask (ent-pred-obj)  \n",
       "4                 Ask (ent-pred-obj`)  \n",
       "...                               ...  \n",
       "30221   <?S P O ; ?S InstanceOf Type>  \n",
       "30222   <S P ?O ; ?O instanceOf Type>  \n",
       "30223   <?S P O ; ?S InstanceOf Type>  \n",
       "30224   <S P ?O ; ?O instanceOf Type>  \n",
       "30225   <?S P O ; ?S InstanceOf Type>  \n",
       "\n",
       "[30226 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "1\n",
      "running\n",
      "2\n",
      "running\n",
      "3\n",
      "running\n",
      "4\n",
      "running\n",
      "5\n",
      "running\n",
      "6\n",
      "running\n",
      "7\n",
      "running\n",
      "8\n",
      "running\n",
      "9\n",
      "running\n",
      "10\n",
      "running\n",
      "11\n",
      "running\n",
      "12\n",
      "running\n",
      "13\n",
      "running\n",
      "14\n",
      "running\n",
      "15\n",
      "running\n",
      "16\n",
      "running\n",
      "17\n",
      "running\n",
      "18\n",
      "running\n",
      "19\n",
      "running\n",
      "20\n",
      "running\n",
      "21\n",
      "running\n",
      "22\n",
      "running\n",
      "23\n",
      "running\n",
      "24\n",
      "running\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "arr = df_new['template'].unique()\n",
    "count = -1\n",
    "for i in arr:\n",
    "    count = count +1\n",
    "    print(\"running\")\n",
    "    print(count)\n",
    "    for index,value in df_new.iterrows():\n",
    "        if value[\"template\"] == i:\n",
    "            df_new.at[index,\"template_key\"] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paraphrased_question</th>\n",
       "      <th>template</th>\n",
       "      <th>template_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did Alexander Hamilton practice law?</td>\n",
       "      <td>Ask (ent-pred-obj)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Does FC Barcelona have Juan Jose Ibarretxe as ...</td>\n",
       "      <td>Ask (ent-pred-obj`)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is Harrelson the real family name of Woody Har...</td>\n",
       "      <td>Ask (ent-pred-obj)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Was Ivonka Trump ever a tv host?</td>\n",
       "      <td>Ask (ent-pred-obj)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Has Rihanna ever recorded for Motown?</td>\n",
       "      <td>Ask (ent-pred-obj`)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30221</th>\n",
       "      <td>Which geographic area is located in East Asia'...</td>\n",
       "      <td>&lt;?S P O ; ?S InstanceOf Type&gt;</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30222</th>\n",
       "      <td>Which company has Skype developed?</td>\n",
       "      <td>&lt;S P ?O ; ?O instanceOf Type&gt;</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30223</th>\n",
       "      <td>Which film is David Bowie's name?</td>\n",
       "      <td>&lt;?S P O ; ?S InstanceOf Type&gt;</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30224</th>\n",
       "      <td>What is the federal state involved in the Cuba...</td>\n",
       "      <td>&lt;S P ?O ; ?O instanceOf Type&gt;</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30225</th>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;?S P O ; ?S InstanceOf Type&gt;</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30226 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    paraphrased_question  \\\n",
       "0                   Did Alexander Hamilton practice law?   \n",
       "1      Does FC Barcelona have Juan Jose Ibarretxe as ...   \n",
       "2      Is Harrelson the real family name of Woody Har...   \n",
       "3                       Was Ivonka Trump ever a tv host?   \n",
       "4                  Has Rihanna ever recorded for Motown?   \n",
       "...                                                  ...   \n",
       "30221  Which geographic area is located in East Asia'...   \n",
       "30222                 Which company has Skype developed?   \n",
       "30223                  Which film is David Bowie's name?   \n",
       "30224  What is the federal state involved in the Cuba...   \n",
       "30225                                                 []   \n",
       "\n",
       "                             template  template_key  \n",
       "0                  Ask (ent-pred-obj)           0.0  \n",
       "1                 Ask (ent-pred-obj`)           1.0  \n",
       "2                  Ask (ent-pred-obj)           0.0  \n",
       "3                  Ask (ent-pred-obj)           0.0  \n",
       "4                 Ask (ent-pred-obj`)           1.0  \n",
       "...                               ...           ...  \n",
       "30221   <?S P O ; ?S InstanceOf Type>          20.0  \n",
       "30222   <S P ?O ; ?O instanceOf Type>          21.0  \n",
       "30223   <?S P O ; ?S InstanceOf Type>          20.0  \n",
       "30224   <S P ?O ; ?O instanceOf Type>          21.0  \n",
       "30225   <?S P O ; ?S InstanceOf Type>          20.0  \n",
       "\n",
       "[30226 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_new[\"template_key\"] = df_new['template_key'].astype(float)\n",
    "df_new[\"template_key\"] = df_new['template_key'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24    3304\n",
       "13    2969\n",
       "12    2943\n",
       "16    2505\n",
       "20    2042\n",
       "18    1923\n",
       "21    1872\n",
       "17    1791\n",
       "19    1672\n",
       "15    1556\n",
       "23    1307\n",
       "22    1307\n",
       "8      768\n",
       "14     740\n",
       "25     740\n",
       "7      656\n",
       "9      377\n",
       "10     377\n",
       "11     377\n",
       "0      318\n",
       "5      212\n",
       "1      173\n",
       "4      147\n",
       "3      125\n",
       "6       16\n",
       "2        9\n",
       "Name: template_key, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[\"template_key\"].value_counts() #6,2,3,4,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new[df_new[\"template_key\"] != 6]\n",
    "df_new = df_new[df_new[\"template_key\"] != 2]\n",
    "df_new = df_new[df_new[\"template_key\"] != 3]\n",
    "df_new = df_new[df_new[\"template_key\"] != 4]\n",
    "df_new = df_new[df_new[\"template_key\"] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "0\n",
      "running\n",
      "1\n",
      "running\n",
      "2\n",
      "running\n",
      "3\n",
      "running\n",
      "4\n",
      "running\n",
      "5\n",
      "running\n",
      "6\n",
      "running\n",
      "7\n",
      "running\n",
      "8\n",
      "running\n",
      "9\n",
      "running\n",
      "10\n",
      "running\n",
      "11\n",
      "running\n",
      "12\n",
      "running\n",
      "13\n",
      "running\n",
      "14\n",
      "running\n",
      "15\n",
      "running\n",
      "16\n",
      "running\n",
      "17\n",
      "running\n",
      "18\n",
      "running\n",
      "19\n",
      "running\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "arr = df_new['template_key'].unique()\n",
    "count = -1\n",
    "for i in arr:\n",
    "    count = count +1\n",
    "    print(\"running\")\n",
    "    print(count)\n",
    "    for index,value in df_new.iterrows():\n",
    "        if value[\"template_key\"] == i:\n",
    "            df_new.at[index,\"template_idd\"] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new[\"template_idd\"] = df_new['template_idd'].astype(float)\n",
    "df_new[\"template_idd\"] = df_new['template_idd'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (3.4.0)\n",
      "Requirement already satisfied: protobuf in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from transformers) (3.13.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from transformers) (2020.10.28)\n",
      "Requirement already satisfied: packaging in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from transformers) (20.1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from transformers) (0.1.94)\n",
      "Requirement already satisfied: tokenizers==0.9.2 in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from transformers) (0.9.2)\n",
      "Requirement already satisfied: sacremoses in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: numpy in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from transformers) (4.46.1)\n",
      "Requirement already satisfied: requests in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: setuptools in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from protobuf->transformers) (46.0.0.post20200309)\n",
      "Requirement already satisfied: six>=1.9 in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from protobuf->transformers) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from packaging->transformers) (2.4.6)\n",
      "Requirement already satisfied: joblib in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import keras\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import confusion_matrix,f1_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import itertools\n",
    "from keras.models import load_model\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import *\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def clean_stopwords_shortwords(w):\n",
    "    stopwords_list=stopwords.words('english')\n",
    "    words = w.split() \n",
    "    clean_words = [word for word in words if (word not in stopwords_list) and len(word) > 2]\n",
    "    return \" \".join(clean_words) \n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "    w = re.sub(r\"([?.!,Â¿])\", r\" \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", w)\n",
    "    w=clean_stopwords_shortwords(w)\n",
    "    w=re.sub(r'@\\w+', '',w)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available labels:  [11 10 14 13  8 12 15  2 16  7  9  0  6 17 20 19 18  5  3  1  4]\n"
     ]
    }
   ],
   "source": [
    "data = df_new.copy() \n",
    "data=data.dropna()                                                           # Drop NaN valuues, if any\n",
    "data=data.reset_index(drop=True)                                             # Reset index after dropping the columns/rows with NaN values\n",
    "data = shuffle(data)                                                         # Shuffle the dataset\n",
    "print('Available labels: ',data.template_idd.unique())                              # Print all the unique labels in the dataset\n",
    "data['paraphrased_question']=data['paraphrased_question'].map(preprocess_sentence)                           # Clean the text column using preprocess_sentence function defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paraphrased_question</th>\n",
       "      <th>template</th>\n",
       "      <th>template_key</th>\n",
       "      <th>template_idd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13627</th>\n",
       "      <td>title parent taxon philodendron goes common title</td>\n",
       "      <td>E REF ?F . ?F RFG G</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10321</th>\n",
       "      <td>many suits ian rush played many desires scored...</td>\n",
       "      <td>[]</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18249</th>\n",
       "      <td>maury aoc produce rate</td>\n",
       "      <td>ASK ?sbj ?pred ?obj filter ?obj = num</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14528</th>\n",
       "      <td>geological locale landmass espoo</td>\n",
       "      <td>E REF xF . xF RFG ?G</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>assassinated malcolm</td>\n",
       "      <td>(E pred ?Obj ) prop value</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18259</th>\n",
       "      <td>genome sized triticum aestivum equals</td>\n",
       "      <td>ASK ?sbj ?pred ?obj filter ?obj = num</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20471</th>\n",
       "      <td>highest constitutional court hamburg</td>\n",
       "      <td>&lt;S P ?O ; ?O instanceOf Type&gt;</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>paolo gentiloni graduate sapienza university rome</td>\n",
       "      <td>(E pred ?Obj ) prop value</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18220</th>\n",
       "      <td>belarus foreign direct investment</td>\n",
       "      <td>ASK ?sbj ?pred ?obj filter ?obj = num</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20513</th>\n",
       "      <td>artistic theme jesus christ followers</td>\n",
       "      <td>&lt;?S P O ; ?S InstanceOf Type&gt;</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29756 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    paraphrased_question  \\\n",
       "13627  title parent taxon philodendron goes common title   \n",
       "10321  many suits ian rush played many desires scored...   \n",
       "18249                             maury aoc produce rate   \n",
       "14528                   geological locale landmass espoo   \n",
       "7998                                assassinated malcolm   \n",
       "...                                                  ...   \n",
       "18259              genome sized triticum aestivum equals   \n",
       "20471               highest constitutional court hamburg   \n",
       "5913   paolo gentiloni graduate sapienza university rome   \n",
       "18220                  belarus foreign direct investment   \n",
       "20513              artistic theme jesus christ followers   \n",
       "\n",
       "                                    template  template_key  template_idd  \n",
       "13627                    E REF ?F . ?F RFG G            16            11  \n",
       "10321                                     []            15            10  \n",
       "18249  ASK ?sbj ?pred ?obj filter ?obj = num            19            14  \n",
       "14528                   E REF xF . xF RFG ?G            18            13  \n",
       "7998               (E pred ?Obj ) prop value            13             8  \n",
       "...                                      ...           ...           ...  \n",
       "18259  ASK ?sbj ?pred ?obj filter ?obj = num            19            14  \n",
       "20471          <S P ?O ; ?O instanceOf Type>            21            16  \n",
       "5913               (E pred ?Obj ) prop value            13             8  \n",
       "18220  ASK ?sbj ?pred ?obj filter ?obj = num            19            14  \n",
       "20513          <?S P O ; ?S InstanceOf Type>            20            15  \n",
       "\n",
       "[29756 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29756, 29756)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences=data['paraphrased_question']\n",
    "labels=data['template_idd']\n",
    "len(sentences),len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertForSequenceClassification: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['dropout_113', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_classes=len(data.template_key.unique())\n",
    "\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "input_ids=[]\n",
    "attention_masks=[]\n",
    "\n",
    "for sent in sentences:\n",
    "    bert_inp=bert_tokenizer.encode_plus(sent,add_special_tokens = True,max_length =64,pad_to_max_length = True,return_attention_mask = True)\n",
    "    input_ids.append(bert_inp['input_ids'])\n",
    "    attention_masks.append(bert_inp['attention_mask'])\n",
    "\n",
    "input_ids=np.asarray(input_ids)\n",
    "attention_masks=np.array(attention_masks)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29756, 29756, 29756)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids),len(attention_masks),len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the pickle file.....\n",
      "Pickle files saved as  bert_inp.pkl bert_mask.pkl bert_label.pkl\n"
     ]
    }
   ],
   "source": [
    "print('Preparing the pickle file.....')\n",
    "\n",
    "pickle_inp_path='bert_inp.pkl'\n",
    "pickle_mask_path='bert_mask.pkl'\n",
    "pickle_label_path='bert_label.pkl'\n",
    "\n",
    "pickle.dump((input_ids),open(pickle_inp_path,'wb'))\n",
    "pickle.dump((attention_masks),open(pickle_mask_path,'wb'))\n",
    "pickle.dump((labels),open(pickle_label_path,'wb'))\n",
    "\n",
    "\n",
    "print('Pickle files saved as ',pickle_inp_path,pickle_mask_path,pickle_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the saved pickle files..\n",
      "Input shape (29756, 64) Attention mask shape (29756, 64) Input label shape (29756,)\n"
     ]
    }
   ],
   "source": [
    "print('Loading the saved pickle files..')\n",
    "\n",
    "input_ids=pickle.load(open(pickle_inp_path, 'rb'))\n",
    "attention_masks=pickle.load(open(pickle_mask_path, 'rb'))\n",
    "labels=pickle.load(open(pickle_label_path, 'rb'))\n",
    "\n",
    "print('Input shape {} Attention mask shape {} Input label shape {}'.format(input_ids.shape,attention_masks.shape,labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train inp shape (23804, 64) Val input shape (5952, 64)\n",
      "Train label shape (23804,) Val label shape (5952,)\n",
      "Train attention mask shape (23804, 64) Val attention mask shape (5952, 64)\n"
     ]
    }
   ],
   "source": [
    "train_inp,val_inp,train_label,val_label,train_mask,val_mask=train_test_split(input_ids,labels,attention_masks,test_size=0.2)\n",
    "\n",
    "print('Train inp shape {} Val input shape {}\\nTrain label shape {} Val label shape {}\\nTrain attention mask shape {} Val attention mask shape {}'.format(train_inp.shape,val_inp.shape,train_label.shape,val_label.shape,train_mask.shape,val_mask.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  16149     \n",
      "=================================================================\n",
      "Total params: 109,498,389\n",
      "Trainable params: 109,498,389\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Bert Model None\n"
     ]
    }
   ],
   "source": [
    "log_dir='tb_bert'\n",
    "model_save_path='bert_model.h5'\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True),keras.callbacks.TensorBoard(log_dir=log_dir)]\n",
    "\n",
    "print('\\nBert Model',bert_model.summary())\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5,epsilon=1e-08)\n",
    "\n",
    "bert_model.compile(loss=loss,optimizer=optimizer,metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/744 [..............................] - ETA: 0s - loss: 3.0005 - accuracy: 0.0938WARNING:tensorflow:From /Users/akshaykumardileep/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "744/744 [==============================] - 4414s 6s/step - loss: 1.8893 - accuracy: 0.4264 - val_loss: 1.4305 - val_accuracy: 0.5361\n",
      "Epoch 2/5\n",
      "744/744 [==============================] - 4384s 6s/step - loss: 1.2189 - accuracy: 0.6055 - val_loss: 1.2554 - val_accuracy: 0.5911\n",
      "Epoch 3/5\n",
      "744/744 [==============================] - 4312s 6s/step - loss: 0.8968 - accuracy: 0.7032 - val_loss: 1.2020 - val_accuracy: 0.6127\n",
      "Epoch 4/5\n",
      "744/744 [==============================] - 4171s 6s/step - loss: 0.6573 - accuracy: 0.7767 - val_loss: 1.2646 - val_accuracy: 0.6211\n",
      "Epoch 5/5\n",
      "744/744 [==============================] - 5605s 8s/step - loss: 0.4797 - accuracy: 0.8341 - val_loss: 1.3548 - val_accuracy: 0.6218\n"
     ]
    }
   ],
   "source": [
    "history=bert_model.fit([train_inp,train_mask],train_label,batch_size=32,epochs=5,validation_data=([val_inp,val_mask],val_label),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
